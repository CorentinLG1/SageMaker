{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script mode on Amazon SageMaker\n",
    "\n",
    "\n",
    "Sript mode is a way to work on Machine learning on Amazon Sagemaker only providing the script for processing, training or inference. In this notebook we will focuse on the lowest level of the Script mode usage that is to say using the base class provided by Amzon SageMaker.\n",
    "\n",
    "This notebook will follow each parts of a usual ML workflow with some explaination of the different SageMaker command used.\n",
    "\n",
    "First we want to import the different packages and load the data to S3 if it is not already done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Region : us-east-1\n"
     ]
    }
   ],
   "source": [
    "#Manage interactions with the Amazon SageMaker APIs and any other AWS services needed\n",
    "session = sagemaker.Session()\n",
    "#see the region in which we work\n",
    "region = session.boto_region_name\n",
    "print(\"AWS Region : {}\".format(region))\n",
    "#get the role of the running session\n",
    "role = sagemaker.get_execution_role()\n",
    "#get the bucket name of the session\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now push the data to S3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "#Upload the dataset to S3\n",
    "prefix = \"data_script_mode\"\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'data/dataset.csv')).upload_file('predictive_maintenance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "\n",
    "This graph sum-up how SageMaker handles the processing task :\n",
    "\n",
    "<img src=\"images/smprocess.PNG\" width=\"600\" height=\"400\">\n",
    "\n",
    "A processing job requires the specification of a path to an input S3 bucket that holds the data to be processed. The job utilizes a provided script to perform the processing task. The resulting output data is then stored in a separate S3 path.\n",
    "\n",
    "S3 effectively manages the job environment by utilizing Docker containers. These containers can either be pre-built containers provided by SageMaker, which are accessible on the Elastic Container Registry (ECR), or custom containers created from custom images that must be pushed to ECR.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SageMaker provide different class to instantiate some processing object to run processing job : \n",
    "\n",
    "<img src=\"images/processing.PNG\" width=\"700\" height=\"500\">\n",
    "\n",
    "We will use the Processor class. To do so we first need to have a docker image in which we get the sript we want to run for processing. Let's build such an image and push it to ECR :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘docker’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir docker\n",
    "!cp processing.py docker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting docker/dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker/dockerfile\n",
    "\n",
    "FROM python:3.7-slim-buster\n",
    "\n",
    "RUN pip3 install pandas scikit-learn imblearn\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "COPY processing.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "ecr_repository = 'sagemaker-processing-container'\n",
    "tag = ':latest'\n",
    "processing_repository_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region, ecr_repository + tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  4.608kB\n",
      "Step 1/4 : FROM python:3.7-slim-buster\n",
      " ---> 099f4583c701\n",
      "Step 2/4 : RUN pip3 install pandas scikit-learn imblearn\n",
      " ---> Using cache\n",
      " ---> 2ccc7b4c985f\n",
      "Step 3/4 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 7cb0c1eac9d8\n",
      "Step 4/4 : COPY processing.py .\n",
      " ---> bc38551ee091\n",
      "Successfully built bc38551ee091\n",
      "Successfully tagged sagemaker-processing-container:latest\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'sagemaker-processing-container' already exists in the registry with id '222978838857'\n",
      "The push refers to repository [222978838857.dkr.ecr.us-east-1.amazonaws.com/sagemaker-processing-container]\n",
      "\n",
      "\u001b[1B058ba0b2: Preparing \n",
      "\u001b[1Be4f6bf59: Preparing \n",
      "\u001b[1B8d012914: Preparing \n",
      "\u001b[1Bd30bdfa9: Preparing \n",
      "\u001b[1B9f968310: Preparing \n",
      "\u001b[1B55769c5e: Preparing \n",
      "\u001b[7B058ba0b2: Pushed lready exists 5kBA\u001b[2K\u001b[7A\u001b[2Klatest: digest: sha256:5e42e8dd0c3d7a60123d937806d9c5eaf5cbb3da713ea1208b96ccc193f95c6b size: 1790\n"
     ]
    }
   ],
   "source": [
    "!docker build -t $ecr_repository docker\n",
    "\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account_id}.dkr.ecr.{region}.amazonaws.com\n",
    "\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "\n",
    "!docker tag {ecr_repository + tag} $processing_repository_uri\n",
    "\n",
    "!docker push $processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One we have our image pushed on ECR, we need to implement a Processor object which will be used to launch the processing job, for more information about the processing class see https://sagemaker.readthedocs.io/en/stable/api/training/processing.html\n",
    "\n",
    "The ProcessingInput class represents an input source for a processing job in Amazon SageMaker. It encapsulates information about the input data location, such as the S3 bucket path, and any optional configurations or preprocessing steps required before the processing job begins.\n",
    "The ProcessingOutput class represents an output destination for a processing job. It contains information about where the processed data should be stored, including the S3 bucket path and any optional configurations or post-processing steps.\n",
    "We can add some argument which are passed with argparse to our processing script. See the processing.py file to have more information about the architecture of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Creating processing-job with name sagemaker-processing-container-2023-06-23-10-03-13-195\n",
      "INFO:sagemaker.local.local_session:Starting processing job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-y06hu:\n",
      "    container_name: xp57q3z8wp-algo-1-y06hu\n",
      "    entrypoint:\n",
      "    - python3\n",
      "    - processing.py\n",
      "    - --train-test-split-ratio\n",
      "    - '0.2'\n",
      "    environment: []\n",
      "    image: 222978838857.dkr.ecr.us-east-1.amazonaws.com/sagemaker-processing-container\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-y06hu\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmp3z4d2tun/algo-1-y06hu/config:/opt/ml/config\n",
      "    - /tmp/tmp3z4d2tun/algo-1-y06hu/output:/opt/ml/output\n",
      "    - /tmp/tmpgz5tlmsl:/opt/ml/processing/input\n",
      "    - /tmp/tmpltl9r8si/output/train_data:/opt/ml/processing/train\n",
      "    - /tmp/tmpltl9r8si/output/test_data:/opt/ml/processing/test\n",
      "    - /tmp/tmp3z4d2tun/shared:/opt/ml/shared\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmp3z4d2tun/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating xp57q3z8wp-algo-1-y06hu ... \n",
      "Creating xp57q3z8wp-algo-1-y06hu ... done\n",
      "Attaching to xp57q3z8wp-algo-1-y06hu\n",
      "\u001b[36mxp57q3z8wp-algo-1-y06hu |\u001b[0m Received arguments Namespace(train_test_split_ratio=0.2)\n",
      "\u001b[36mxp57q3z8wp-algo-1-y06hu |\u001b[0m Reading input data from /opt/ml/processing/input/dataset.csv\n",
      "\u001b[36mxp57q3z8wp-algo-1-y06hu |\u001b[0m Splitting data into train and test sets with ratio 0.2\n",
      "\u001b[36mxp57q3z8wp-algo-1-y06hu |\u001b[0m Resampling the dataset...\n",
      "\u001b[36mxp57q3z8wp-algo-1-y06hu |\u001b[0m Scaling the dataset...\n",
      "\u001b[36mxp57q3z8wp-algo-1-y06hu exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import Processor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "#first we instanciate the processor with the image uri of our ECR image, and as described above, we need to provide the entrypoint of the docker container\n",
    "processor = Processor(\n",
    "    role = role,\n",
    "    image_uri = \"222978838857.dkr.ecr.us-east-1.amazonaws.com/sagemaker-processing-container\",\n",
    "    instance_count = 1,\n",
    "    instance_type = \"local\",\n",
    "    entrypoint = [\"python3\", \"processing.py\"]\n",
    "    )\n",
    "#The path of our S3 bucket\n",
    "bucket_path = 's3://{}'.format(bucket)\n",
    "\n",
    "#we then launch the processing job\n",
    "processor.run(\n",
    "    inputs=[ProcessingInput(source=f\"{bucket_path}/{prefix}/data/dataset.csv\", destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    arguments=[\"--train-test-split-ratio\", \"0.2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One the job is completed, we can retrieve some information about it, espacially get the S3 path of the output data so that we can use it for the training :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-222978838857/sagemaker-processing-container-2023-06-23-10-03-13-195/output/train_data\n",
      "Training features shape: (10, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.558041</td>\n",
       "      <td>-1.176855</td>\n",
       "      <td>-1.099352</td>\n",
       "      <td>0.289338</td>\n",
       "      <td>-1.086507</td>\n",
       "      <td>-1.096994</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.558041</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>-0.269350</td>\n",
       "      <td>0.103445</td>\n",
       "      <td>-0.516629</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.193990</td>\n",
       "      <td>1.595951</td>\n",
       "      <td>1.994294</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>-0.822939</td>\n",
       "      <td>-1.532886</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.193990</td>\n",
       "      <td>-1.484944</td>\n",
       "      <td>-1.325717</td>\n",
       "      <td>-0.410296</td>\n",
       "      <td>0.302572</td>\n",
       "      <td>-0.872017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.193990</td>\n",
       "      <td>-0.817417</td>\n",
       "      <td>-0.722078</td>\n",
       "      <td>-0.362978</td>\n",
       "      <td>-0.039355</td>\n",
       "      <td>0.210683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.558041</td>\n",
       "      <td>0.106852</td>\n",
       "      <td>1.164291</td>\n",
       "      <td>-0.068929</td>\n",
       "      <td>-0.445394</td>\n",
       "      <td>1.124650</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.558041</td>\n",
       "      <td>-1.125506</td>\n",
       "      <td>-0.872988</td>\n",
       "      <td>-0.001331</td>\n",
       "      <td>-0.552246</td>\n",
       "      <td>-1.181360</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.558041</td>\n",
       "      <td>-0.098541</td>\n",
       "      <td>0.862472</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>-0.281554</td>\n",
       "      <td>-0.281453</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.193990</td>\n",
       "      <td>-1.536293</td>\n",
       "      <td>-0.722078</td>\n",
       "      <td>0.035848</td>\n",
       "      <td>-0.331418</td>\n",
       "      <td>1.138711</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>2.946020</td>\n",
       "      <td>-1.330900</td>\n",
       "      <td>-1.853900</td>\n",
       "      <td>0.333277</td>\n",
       "      <td>-0.623481</td>\n",
       "      <td>-0.464247</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5   \n",
       "0           1 -0.558041 -1.176855 -1.099352  0.289338 -1.086507 -1.096994  \\\n",
       "1           2 -0.558041  0.004155 -0.269350  0.103445 -0.516629  0.323171   \n",
       "2           3  1.193990  1.595951  1.994294  0.573248 -0.822939 -1.532886   \n",
       "3           4  1.193990 -1.484944 -1.325717 -0.410296  0.302572 -0.872017   \n",
       "4           5  1.193990 -0.817417 -0.722078 -0.362978 -0.039355  0.210683   \n",
       "5           6 -0.558041  0.106852  1.164291 -0.068929 -0.445394  1.124650   \n",
       "6           7 -0.558041 -1.125506 -0.872988 -0.001331 -0.552246 -1.181360   \n",
       "7           8 -0.558041 -0.098541  0.862472  0.018948 -0.281554 -0.281453   \n",
       "8           9  1.193990 -1.536293 -0.722078  0.035848 -0.331418  1.138711   \n",
       "9          11  2.946020 -1.330900 -1.853900  0.333277 -0.623481 -0.464247   \n",
       "\n",
       "   Target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "5     0.0  \n",
       "6     0.0  \n",
       "7     0.0  \n",
       "8     0.0  \n",
       "9     0.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_job_description = processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"train_data\":\n",
    "        preprocessed_training_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "    if output[\"OutputName\"] == \"test_data\":\n",
    "        preprocessed_test_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "        \n",
    "        \n",
    "print(preprocessed_training_data)\n",
    "#Observe the processed data \n",
    "training_features = pd.read_csv(preprocessed_training_data + \"/dataset_train.csv\",nrows=10)\n",
    "print(\"Training features shape: {}\".format(training_features.shape))\n",
    "training_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The training part is similar to the processing part in the code but has some difference on the way SageMaker handles the task.\n",
    "\n",
    "<img src=\"images/training.PNG\" width=\"500\" height=\"700\">\n",
    "\n",
    "(1) On the Jupyter Notebook, you need to instanciate the training object to make the API call to SageMaker, push the data to S3 if needed, and push the image to ECR if needed.\n",
    "\n",
    "\n",
    "(2) One you run the fit method of the estimator you instanciated, you call the SageMaker API with the create_training_job request (see : https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_training_job.html), SageMaker launch the EC2 instance with the information you provided in the request (which is basicaly a json file since we work with RESTful API)\n",
    "\n",
    "(3) The training job run on the EC2 instance, when it has finished, it stores the output on a S3 bucket (model artifact, logs...) and shutdown every instance.\n",
    "\n",
    "(4) All the training outputs are available on a S3 bucket and the model is ready to be deployed on an endpoint\n",
    "\n",
    "\n",
    "\n",
    "In our case, we load a SageMaker image from ECR and use it for training. Then we just have to provide the training script as the entrypoit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Creating training-job with name: job-2023-06-23-10-03-26-412\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-3msu4:\n",
      "    command: train\n",
      "    container_name: kj86d2edkr-algo-1-3msu4\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-3msu4\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpypeo_72x/algo-1-3msu4/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpypeo_72x/algo-1-3msu4/input:/opt/ml/input\n",
      "    - /tmp/tmpypeo_72x/algo-1-3msu4/output:/opt/ml/output\n",
      "    - /tmp/tmpypeo_72x/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /tmp/tmps26wdoze:/opt/ml/input/data/train\n",
      "    - /tmp/tmpmhyfvqov:/opt/ml/input/data/test\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpypeo_72x/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating kj86d2edkr-algo-1-3msu4 ... \n",
      "Creating kj86d2edkr-algo-1-3msu4 ... done\n",
      "Attaching to kj86d2edkr-algo-1-3msu4\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,153 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,158 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,159 sagemaker-training-toolkit INFO     Failed to parse hyperparameter kernel value poly to Json.\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m Returning the value itself\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,170 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,486 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,487 sagemaker-training-toolkit INFO     Failed to parse hyperparameter kernel value poly to Json.\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m Returning the value itself\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,500 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,501 sagemaker-training-toolkit INFO     Failed to parse hyperparameter kernel value poly to Json.\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m Returning the value itself\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,513 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,514 sagemaker-training-toolkit INFO     Failed to parse hyperparameter kernel value poly to Json.\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m Returning the value itself\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:30,525 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m \n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m Training Env:\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m \n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m {\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     },\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"current_host\": \"algo-1-3msu4\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         \"algo-1-3msu4\"\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     ],\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         \"C\": 1,\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         \"kernel\": \"poly\"\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     },\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         \"train\": {\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         },\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         \"test\": {\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         }\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     },\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"job_name\": \"job-2023-06-23-10-03-26-412\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"master_hostname\": \"algo-1-3msu4\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-222978838857/job-2023-06-23-10-03-26-412/source/sourcedir.tar.gz\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         \"current_host\": \"algo-1-3msu4\",\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m             \"algo-1-3msu4\"\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m         ]\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     },\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m }\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m \n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m Environment variables:\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m \n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_HOSTS=[\"algo-1-3msu4\"]\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_HPS={\"C\":1,\"kernel\":\"poly\"}\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-3msu4\",\"hosts\":[\"algo-1-3msu4\"]}\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_CURRENT_HOST=algo-1-3msu4\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-222978838857/job-2023-06-23-10-03-26-412/source/sourcedir.tar.gz\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-3msu4\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-3msu4\"],\"hyperparameters\":{\"C\":1,\"kernel\":\"poly\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"job-2023-06-23-10-03-26-412\",\"log_level\":20,\"master_hostname\":\"algo-1-3msu4\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-222978838857/job-2023-06-23-10-03-26-412/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-3msu4\",\"hosts\":[\"algo-1-3msu4\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_USER_ARGS=[\"-C\",\"1\",\"--kernel\",\"poly\"]\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_HP_C=1\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m SM_HP_KERNEL=poly\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m \n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m \n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m /miniconda3/bin/python train.py -C 1 --kernel poly\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m \n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m accuracy on test is : 0.9651474530831099\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:31,719 - INFO - Accuracy : 0.9651474530831099\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:31,719 - INFO - saving the model...\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:31,722 - INFO - Training complete.\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 |\u001b[0m 2023-06-23 10:03:31,944 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mkj86d2edkr-algo-1-3msu4 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /tmp/tmpypeo_72x/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmpypeo_72x/algo-1-3msu4/output/success -> /tmp/tmpypeo_72x/artifacts/output\n",
      "INFO:root:copying /tmp/tmpypeo_72x/model/model.joblib -> /tmp/tmpypeo_72x/artifacts/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "training_image = image_uris.retrieve(framework='sklearn',region='us-east-1',version='1.2-1',image_scope='training')\n",
    "\n",
    "\n",
    "metric = {\n",
    "    'Name' : 'Accuracy', 'Regex' : 'Accuracy : ([0-9\\\\.]+)'\n",
    "}\n",
    "\n",
    "estimator = Estimator(\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"local\",\n",
    "    base_job_name = \"job\",\n",
    "    image_uri = training_image,\n",
    "    entry_point = \"train.py\",\n",
    "    metric_definitions = [metric]\n",
    ")\n",
    "\n",
    "estimator.set_hyperparameters(\n",
    "    C = 1,\n",
    "    kernel = \"poly\"\n",
    ")\n",
    "\n",
    "\n",
    "estimator.fit({\"train\" : preprocessed_training_data, \"test\" : preprocessed_test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the processing, we can retrieve some information about the job. For example, the S3 path of our model to use it for inference if we want to use a custom inference script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-222978838857/job-2023-06-23-10-03-26-412/model.tar.gz'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_job_description = estimator.jobs[-1].describe()\n",
    "training_job_description\n",
    "model_data_s3_uri = \"{}\".format(training_job_description[\"ModelArtifacts\"][\"S3ModelArtifacts\"])\n",
    "model_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy\n",
    "\n",
    "Once the training is done, our model is ready to be deployed to and enpoint. We could directly use the deploy() method on our estimator but here we have not implemented an inference part in our training script and we want to use a different image for training and inference.\n",
    "We will use the class Model to deploy our model to an enpoint :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "inference_image = image_uris.retrieve(framework='sklearn',region='us-east-1',version='1.2-1',image_scope='inference')\n",
    "\n",
    "model = Model(\n",
    "    image_uri = inference_image,\n",
    "    model_data = model_data_s3_uri,\n",
    "    role = role,\n",
    "    entry_point = \"inference.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Creating model with name: sagemaker-scikit-learn-2023-06-23-10-03-44-097\n",
      "INFO:sagemaker:Creating endpoint-config with name myendpoint\n",
      "INFO:sagemaker:Creating endpoint with name myendpoint\n",
      "INFO:sagemaker.local.image:serving\n",
      "INFO:sagemaker.local.image:creating hosting dir in /tmp/tmpj3ohlxzo\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-4jqzs:\n",
      "    command: serve\n",
      "    container_name: o4afpz6lbw-algo-1-4jqzs\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-4jqzs\n",
      "    ports:\n",
      "    - 8080:8080\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmp2ypr70mt:/opt/ml/model\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpj3ohlxzo/docker-compose.yaml up --build --abort-on-container-exit\n",
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 5\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff4695aec20>: Failed to establish a new connection: [Errno 111] Connection refused')': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff4695af640>: Failed to establish a new connection: [Errno 111] Connection refused')': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff4695acac0>: Failed to establish a new connection: [Errno 111] Connection refused')': /ping\n",
      "INFO:sagemaker.local.entities:Container still not up, got: -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to o4afpz6lbw-algo-1-4jqzs\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 2023-06-23 10:03:46,981 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 2023-06-23 10:03:46,985 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 2023-06-23 10:03:46,986 INFO - sagemaker-containers - nginx config: \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m worker_processes auto;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m daemon off;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m pid /tmp/nginx.pid;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m error_log  /dev/stderr;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m worker_rlimit_nofile 4096;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m events {\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   worker_connections 2048;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m }\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m http {\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   include /etc/nginx/mime.types;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   default_type application/octet-stream;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   access_log /dev/stdout combined;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   upstream gunicorn {\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m     server unix:/tmp/gunicorn.sock;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   }\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   server {\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m     listen 8080 deferred;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m     client_max_body_size 0;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m     keepalive_timeout 3;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m       proxy_set_header Host $http_host;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m       proxy_redirect off;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m       proxy_read_timeout 60s;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m       proxy_pass http://gunicorn;\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m     }\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m     location / {\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m       return 404 \"{}\";\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m     }\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   }\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m }\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 2023-06-23 10:03:47,235 INFO - sagemaker-containers - Module inference does not provide a setup.py. \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m Generating setup.py\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 2023-06-23 10:03:47,235 INFO - sagemaker-containers - Generating setup.cfg\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 2023-06-23 10:03:47,235 INFO - sagemaker-containers - Generating MANIFEST.in\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 2023-06-23 10:03:47,235 INFO - sagemaker-containers - Installing module with the following command:\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m /miniconda3/bin/python3 -m pip install . \n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \u001b[?25hBuilding wheels for collected packages: inference\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   Building wheel for inference (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m \u001b[?25h  Created wheel for inference: filename=inference-1.0.0-py2.py3-none-any.whl size=3891 sha256=95a7de012b8627033fe6b744b536dc02ef9d3ba06df84061243f6a39a1e548fd\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-iungaj9y/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m Successfully built inference\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m Installing collected packages: inference\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m Successfully installed inference-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 10\n",
      "INFO:sagemaker.local.entities:Container still not up, got: 502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 2023/06/23 10:03:49 [crit] 14#14: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"localhost:8080\"\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 172.18.0.1 - - [23/Jun/2023:10:03:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"python-urllib3/1.26.14\"\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m [2023-06-23 10:03:50 +0000] [27] [INFO] Starting gunicorn 20.0.4\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m [2023-06-23 10:03:50 +0000] [27] [INFO] Listening at: unix:/tmp/gunicorn.sock (27)\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m [2023-06-23 10:03:50 +0000] [27] [INFO] Using worker: gevent\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m [2023-06-23 10:03:50 +0000] [29] [INFO] Booting worker with pid: 29\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m [2023-06-23 10:03:50 +0000] [30] [INFO] Booting worker with pid: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 2023-06-23 10:03:54,530 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mo4afpz6lbw-algo-1-4jqzs |\u001b[0m 172.18.0.1 - - [23/Jun/2023:10:03:55 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.14\"\n",
      "!"
     ]
    }
   ],
   "source": [
    "\n",
    "predictor = model.deploy(    \n",
    "    initial_instance_count = 1,\n",
    "    instance_type = \"local\",\n",
    "    endpoint_name = \"myendpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
